{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Pocket2Mol on a PDB file\n",
        "\n",
        "colab by [@btnaughton](https://twitter.com/btnaughton)"
      ],
      "metadata": {
        "id": "gVY7PyBmRigI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PDB + SMILES input\n",
        "\n",
        "PDB_ID = '' #@param {type:\"string\"}\n",
        "LIG_ID = '' #@param {type:\"string\"}\n",
        "CHAIN = '' #@param {type:\"string\"}\n",
        "\n",
        "# markdown Download a tar file containing all results?\n",
        "# download_results = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "n7St-I2vGVJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install prerequisites"
      ],
      "metadata": {
        "id": "p4ShLcvYG4AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime --quiet\n",
        "%load_ext autotime\n",
        "!pip install rdkit biopython pyyaml easydict tensorboard lmdb gdown prody pypdb --quiet #  replaced python-lmdb with lmdb"
      ],
      "metadata": {
        "id": "fRx0G_8hSBVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"torch version {torch.__version__}\")\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet"
      ],
      "metadata": {
        "id": "KOuljejMS2aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Install Pocket2Mol"
      ],
      "metadata": {
        "id": "2ttsBRV1A3kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pengxingang/Pocket2Mol --quiet"
      ],
      "metadata": {
        "id": "HMrmRTUASJnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Pocket2Mol/data\n",
        "!test -f crossdocked_pocket10.tar.gz || gdown 10KGuj15mxOJ2FBsduun2Lggzx0yPreEU && tar -xzf crossdocked_pocket10.tar.gz\n",
        "!test -f split_by_name.pt || gdown 1mycOKpphVBQjxEbpn1AwdpQs8tNVbxKY\n",
        "!ls -l"
      ],
      "metadata": {
        "id": "iYZ-13yoVHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Pocket2Mol/ckpt\n",
        "!test -f pretrained_Pocket2Mol.pt || gdown 1WaoEj9RDG4VEcyHEmgsjbh958txm1W6x\n",
        "!ls -l"
      ],
      "metadata": {
        "id": "8Eb7uzcrYRk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility PDB functions"
      ],
      "metadata": {
        "id": "lk2DpMS5A-hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "from random import random\n",
        "\n",
        "def download_pdb_file(pdb_id: str) -> str:\n",
        "    \"\"\"Download pdb file as a string from rcsb.org\"\"\"\n",
        "    PDB_DIR =\"/tmp/pdb/\"\n",
        "    os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "    # url or pdb_id\n",
        "    if pdb_id.startswith('http'):\n",
        "        url = pdb_id\n",
        "        filename = url.split('/')[-1]\n",
        "    elif pdb_id.endswith(\".pdb\"):\n",
        "        return pdb_id\n",
        "    else:\n",
        "        if pdb_id.startswith(\"AF\"):\n",
        "            url = f\"https://alphafold.ebi.ac.uk/files/{pdb_id}-model_v3.pdb\"\n",
        "        else:\n",
        "            url = f\"http://files.rcsb.org/view/{pdb_id}.pdb\"\n",
        "        filename = f'{pdb_id}.pdb'\n",
        "\n",
        "    cache_path = os.path.join(PDB_DIR, filename)\n",
        "    if os.path.exists(cache_path):\n",
        "        return cache_path\n",
        "\n",
        "    pdb_req = requests.get(url)\n",
        "    pdb_req.raise_for_status()\n",
        "    open(cache_path, 'w').write(pdb_req.text)\n",
        "    return cache_path"
      ],
      "metadata": {
        "id": "EM61LNA-X0Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "import os\n",
        "import sys\n",
        "from typing import Iterable\n",
        "\n",
        "import pandas as pd\n",
        "from prody import parsePDB, writePDB, writePDBStream\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import requests\n",
        "\n",
        "\n",
        "LIGAND_EXPO_FILENAME = \"Components-smiles-stereo-oe.smi\"\n",
        "LIGAND_EXPO_URL = f\"http://ligand-expo.rcsb.org/dictionaries/{LIGAND_EXPO_FILENAME}\"\n",
        "\n",
        "def _read_ligand_expo():\n",
        "    \"\"\"\n",
        "    Read Ligand Expo data, try to find a file called\n",
        "    Components-smiles-stereo-oe.smi in the current directory.\n",
        "    If you can't find the file, grab it from the RCSB (archived in gs://hx-brian 2023-06-11)\n",
        "    :return: Ligand Expo as a dictionary with ligand id as the key\n",
        "    \"\"\"\n",
        "    if not os.path.exists(LIGAND_EXPO_FILENAME):\n",
        "        with open(LIGAND_EXPO_FILENAME, 'wb') as out:\n",
        "            r = requests.get(LIGAND_EXPO_URL, allow_redirects=True)\n",
        "            out.write(r.content)\n",
        "\n",
        "    df = pd.read_csv(LIGAND_EXPO_FILENAME, sep=\"\\t\",\n",
        "                     header=None,\n",
        "                     names=[\"SMILES\", \"ID\", \"Name\"])\n",
        "\n",
        "    df.set_index(\"ID\", inplace=True)\n",
        "\n",
        "    return df.to_dict()\n",
        "\n",
        "\n",
        "def _get_pdb_components(pdb_id):\n",
        "    \"\"\"\n",
        "    Split a protein-ligand pdb into protein and ligand components\n",
        "    :param pdb_id:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    pdb = parsePDB(pdb_id)\n",
        "    protein = pdb.select('protein')\n",
        "    ligand = pdb.select('not protein and not water')\n",
        "    return protein, ligand\n",
        "\n",
        "\n",
        "def _process_ligand(ligand, res_name, expo_dict,\n",
        "                    chain=None):\n",
        "    \"\"\"\n",
        "    Add bond orders to a pdb ligand\n",
        "    1. Select the ligand component with name \"res_name\"\n",
        "    2. Get the corresponding SMILES from the Ligand Expo dictionary\n",
        "    3. Create a template molecule from the SMILES in step 2\n",
        "    4. Write the PDB file to a stream\n",
        "    5. Read the stream into an RDKit molecule\n",
        "    6. Assign the bond orders from the template from step 3\n",
        "    :param ligand: ligand as generated by prody\n",
        "    :param res_name: residue name of ligand to extract\n",
        "    :param expo_dict: dictionary with LigandExpo\n",
        "    :return: molecule with bond orders assigned\n",
        "    \"\"\"\n",
        "\n",
        "    # If you include all chains then the SDF includes multiple molecules\n",
        "    # and it looks messed up\n",
        "    if chain is None:\n",
        "        print(\"No chain given, defaulting to chain A. \"\n",
        "              \"Not specifying a chain can result in multiple molecules combined into one SDF file\", file=sys.stderr)\n",
        "        chain = \"A\"\n",
        "\n",
        "    output = StringIO()\n",
        "    sub_mol = ligand.select(f\"resname {res_name} and chain {chain}\")\n",
        "    if sub_mol is None:\n",
        "        print(f\"sub_mol is None for {res_name}\")\n",
        "        return None\n",
        "\n",
        "    sub_smiles = expo_dict['SMILES'][res_name]\n",
        "    print(\"smiles:\", sub_smiles, file=sys.stderr)\n",
        "\n",
        "    template = AllChem.MolFromSmiles(sub_smiles)\n",
        "    if template is None:\n",
        "        print(f\"template is None for {sub_smiles}. Returning None.\", file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "    writePDBStream(output, sub_mol)\n",
        "    pdb_string = output.getvalue()\n",
        "    rd_mol = AllChem.MolFromPDBBlock(pdb_string)\n",
        "    new_mol = AllChem.AssignBondOrdersFromTemplate(template, rd_mol)\n",
        "\n",
        "    return new_mol, sub_smiles\n",
        "\n",
        "\n",
        "def _write_pdb(protein, pdb_name,\n",
        "               output_pdb_name=None):\n",
        "    \"\"\"\n",
        "    Write a prody protein to a pdb file\n",
        "    :param protein: protein object from prody\n",
        "    :param pdb_name: base name for the pdb file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    output_pdb_name = output_pdb_name or f\"{pdb_name}_protein.pdb\"\n",
        "    writePDB(f\"{output_pdb_name}\", protein)\n",
        "    print(f\"wrote pdb: {output_pdb_name}\")\n",
        "    return output_pdb_name\n",
        "\n",
        "\n",
        "def _write_sdf(new_mol, pdb_name:str, res_name:str,\n",
        "               output_sdf_name:str|None=None) -> str:\n",
        "    \"\"\"\n",
        "    Write an RDKit molecule to an SD file\n",
        "    :param new_mol:\n",
        "    :param pdb_name:\n",
        "    :param res_name:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    output_sdf_name = output_sdf_name or f\"{pdb_name}_{res_name}_ligand.sdf\"\n",
        "    writer = Chem.SDWriter(f\"{output_sdf_name}\")\n",
        "    writer.write(new_mol)\n",
        "    print(f\"wrote ligand sdf: {output_sdf_name}\\n\")\n",
        "    return output_sdf_name\n",
        "\n",
        "\n",
        "def extract_ligands(pdb_name:str,\n",
        "                    ligand_names:Iterable[str]|None=None,\n",
        "                    chains:Iterable[str]|None=None,\n",
        "                    output_pdb_name:str|None=None,\n",
        "                    output_sdf_name:str|None=None) -> tuple[str, list[str], list[str]]:\n",
        "    \"\"\"\n",
        "    Read Ligand Expo data, split pdb into protein and ligands,\n",
        "    write protein pdb, write ligand sdf files\n",
        "    :param pdb_name: id from the pdb, doesn't need to have an extension\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if chains is not None:\n",
        "        assert ligand_names is not None, \"chains requires ligand_names\"\n",
        "        assert len(chains) == len(ligand_names), \"chains and ligand_names must be the same length\"\n",
        "\n",
        "    # ----------------------------\n",
        "    # First write out protein part\n",
        "    #\n",
        "    df_dict = _read_ligand_expo()\n",
        "    protein_sel, ligand_sel = _get_pdb_components(pdb_name)\n",
        "    # write out the pdb with no ligands\n",
        "    out_pdb_file = _write_pdb(protein_sel, pdb_name, output_pdb_name=output_pdb_name)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Then write out ligands\n",
        "    #\n",
        "    res_name_list = list(set(ligand_sel.getResnames()))\n",
        "    out_sdf_files = []\n",
        "    out_sdf_smiles = []\n",
        "\n",
        "    for res_name in res_name_list:\n",
        "        if ligand_names is not None and res_name not in ligand_names:\n",
        "            continue\n",
        "\n",
        "        if chains is not None:\n",
        "            chain = chains[ligand_names.index(res_name)]\n",
        "        else:\n",
        "            chain = None\n",
        "\n",
        "        new_mol, new_mol_smiles = _process_ligand(ligand_sel, res_name, df_dict, chain)\n",
        "        if new_mol is None:\n",
        "            print(f\"_process_ligand failed for {res_name}. Skipping\")\n",
        "            continue\n",
        "\n",
        "        out_sdf_files.append(_write_sdf(new_mol, pdb_name, res_name, output_sdf_name=output_sdf_name))\n",
        "        out_sdf_smiles.append(new_mol_smiles)\n",
        "\n",
        "    return out_pdb_file, out_sdf_files, out_sdf_smiles\n",
        "\n",
        "\n",
        "def extract_ligand(pdb_name:str, ligand_name:str,\n",
        "                   chain=None,\n",
        "                   output_pdb_name:str|None=None,\n",
        "                   output_sdf_name:str|None=None) -> tuple[str, str, str]:\n",
        "    \"\"\"extract_ligands wrapper for a single ligand\"\"\"\n",
        "    out_pdb_file, out_sdf_files, out_sdf_smileses = extract_ligands(pdb_name, [ligand_name],\n",
        "                                                                    [chain] if chain is not None else None,\n",
        "                                                                    output_pdb_name,\n",
        "                                                                    output_sdf_name)\n",
        "\n",
        "    # add a title\n",
        "    for out_sdf_file, out_sdf_smiles in zip(out_sdf_files, out_sdf_smileses):\n",
        "      lines = open(out_sdf_file).readlines()\n",
        "      lines[0] = f\"{ligand_name}\\t{out_sdf_smiles}\\n\"\n",
        "      open(out_sdf_file, 'w').write(''.join(lines))\n",
        "\n",
        "    return out_pdb_file, out_sdf_files[0], out_sdf_smileses[0]\n",
        "\n",
        "\n",
        "def extract_all_ligands(pdb_name, lig_id=None):\n",
        "    \"\"\"\n",
        "    Read Ligand Expo data, split pdb into protein and ligands,\n",
        "    write protein pdb, write ligand sdf files\n",
        "    :param pdb_name: id from the pdb, doesn't need to have an extension\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    protein, ligand = _get_pdb_components(pdb_name)\n",
        "    output_pdb_name = _write_pdb(protein, pdb_name)\n",
        "\n",
        "    res_name_list = list(set(ligand.getResnames()))\n",
        "    df_dict = _read_ligand_expo()\n",
        "\n",
        "    output_sdf_names = []\n",
        "    for res in res_name_list:\n",
        "        if lig_id is not None and res != lig_id: continue\n",
        "\n",
        "        print(ligand, res, str(df_dict)[:20])\n",
        "        new_mol, new_mol_smiles = _process_ligand(ligand, res, df_dict)\n",
        "        print(\"new_mol\", new_mol)\n",
        "        output_sdf_name = _write_sdf(new_mol, pdb_name, res)\n",
        "        # add a title\n",
        "        lines = open(output_sdf_name).readlines()\n",
        "        lines[0] = f\"{res}\\t{new_mol_smiles}\\n\"\n",
        "        open(output_sdf_name, 'w').write(''.join(lines))\n",
        "        output_sdf_names.append(output_sdf_name)\n",
        "\n",
        "    return output_pdb_name, output_sdf_names"
      ],
      "metadata": {
        "id": "DN22I2qC1KPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Pocket2Mol\n",
        "\n",
        "if PDB_ID == '':\n",
        "  print(\"## Running example: \")\n",
        "  PDB_ID = \"7S15\"\n",
        "  LIG_ID = \"82L\"\n",
        "  CHAIN = \"R\"\n",
        "\n",
        "pdb_file = download_pdb_file(PDB_ID)\n",
        "pdb_nohet_file, pdb_het_file, pdb_het_smiles = extract_ligand(pdb_file, LIG_ID, chain=CHAIN)"
      ],
      "metadata": {
        "id": "cqOxJjAzccam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract centroid from SDF file"
      ],
      "metadata": {
        "id": "Wo6s2zLnTCcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_coords = []\n",
        "for line in open(pdb_het_file).readlines()[4:]:\n",
        "  if len(line.split()) < 4: continue\n",
        "  *coords_str, atom = line.split()[:4]\n",
        "  if atom == \"C\":\n",
        "    all_coords.append([float(x) for x in coords_str])\n",
        "\n",
        "sdf_centroid = np.array(all_coords).mean(axis=0)\n",
        "print(sdf_centroid)"
      ],
      "metadata": {
        "id": "jFBHkrRFfrHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Pocket2Mol\n",
        "\n",
        "# example\n",
        "#!python sample_for_pdb.py --pdb_path \"4yhj.pdb\" --center \" 32.0,28.0,36.0\" # e.g., 4yhj\n",
        "\n",
        "# replace seed with new seed every time\n",
        "from random import randint\n",
        "num_samples = 100\n",
        "!sed -i -E s/\"seed: [0-9]+\"/\"seed: {randint(1, 10000)}\"/ configs/sample_for_pdb.yml\n",
        "!sed -i -E s/\"num_samples: [0-9]+\"/\"num_samples: {num_samples}\"/ configs/sample_for_pdb.yml\n",
        "\n",
        "centroid_str = '\" ' + ','.join(str(x) for x in sdf_centroid) + '\"'\n",
        "!python sample_for_pdb.py --pdb_path {pdb_nohet_file} --center {centroid_str}"
      ],
      "metadata": {
        "id": "4cwHgkLhXdhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install and run gnina to get affinities"
      ],
      "metadata": {
        "id": "UnyX8trwHwS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Pocket2Mol\n",
        "!wget https://sourceforge.net/projects/smina/files/smina.static/download --quiet -O smina && chmod +x smina\n",
        "!wget https://github.com/gnina/gnina/releases/download/v1.0.3/gnina --quiet -O gnina && chmod +x gnina"
      ],
      "metadata": {
        "id": "XTN-1KhTkwTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from itertools import chain as ichain\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "rows = []\n",
        "output_dir = sorted(glob.glob(\"outputs/sample_for_pdb*\"))[-1]\n",
        "smileses = [l.strip() for l in open(f\"{output_dir}/SMILES.txt\")]\n",
        "\n",
        "for sdf_file in tqdm(list(ichain([pdb_het_file], glob.glob(f\"{output_dir}/SDF/*.sdf\")))):\n",
        "\n",
        "  if \"_ligand\" in sdf_file:\n",
        "    print(sdf_file)\n",
        "    _, smiles = open(sdf_file).readlines()[0].strip().split('\\t')\n",
        "  else:\n",
        "    smiles_num = int(re.findall(fr\"{output_dir}/SDF/(.+)\\.sdf\", sdf_file)[0])\n",
        "    smiles = smileses[smiles_num]\n",
        "\n",
        "  mol_wt = Descriptors.ExactMolWt(Chem.MolFromSmiles(smiles))\n",
        "\n",
        "  scored_stdout = !/content/Pocket2Mol/gnina --score_only -r \"{pdb_nohet_file}\" -l \"{sdf_file}\"\n",
        "  scored_affinity = re.findall(r\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(scored_stdout))[0]\n",
        "  minimized_stdout = !/content/Pocket2Mol/gnina --local_only --minimize -r \"{pdb_nohet_file}\" -l \"{sdf_file}\" --autobox_ligand \"{sdf_file}\" --autobox_add 2\n",
        "  minimized_affinity = re.findall(r\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(minimized_stdout))[0]\n",
        "  rows.append((pdb_file.split('/')[-1], sdf_file.split('/')[-1], smiles, float(scored_affinity), float(minimized_affinity), mol_wt))\n",
        "\n",
        "\n",
        "df_aff = (pd.DataFrame(rows, columns=[\"pdb\", \"sdf\", \"smiles\", \"scored_affinity\", \"minimized_affinity\", \"mol_wt\"])\n",
        "            .assign(scored_lig_eff = lambda df: df.scored_affinity / df.mol_wt)\n",
        "            .assign(minimized_lig_eff = lambda df: df.scored_affinity / df.mol_wt)\n",
        "            .sort_values(\"minimized_lig_eff\")\n",
        ")\n",
        "\n",
        "with pd.option_context('display.max_colwidth', None, 'display.max_rows', None, 'display.max_columns', None):\n",
        "  display(df_aff.head(10))"
      ],
      "metadata": {
        "id": "oMtx3GiWlDsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize top hit with Py3DMol"
      ],
      "metadata": {
        "id": "05D3o8KFn_17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py3dmol --upgrade"
      ],
      "metadata": {
        "id": "P8rm1rCBZx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_hit = df_aff.sort_values(\"minimized_affinity\").loc[lambda df: ~df.sdf.str.contains(\"_ligand\")].iloc[0]\n",
        "display(pd.DataFrame(top_hit))\n",
        "top_sdf_file = f'{output_dir}/SDF/{top_hit.sdf}'"
      ],
      "metadata": {
        "id": "OTPfLV-XkPDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import py3Dmol\n",
        "\n",
        "resid_hover = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(!atom.label) {\n",
        "        atom.label = viewer.addLabel(atom.chain+\" \"+atom.resn+\" \"+atom.resi,\n",
        "            {position: atom, backgroundColor: 'mintcream', fontColor:'black', fontSize:12});\n",
        "    }\n",
        "}\"\"\"\n",
        "unhover_func = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(atom.label) {\n",
        "        viewer.removeLabel(atom.label);\n",
        "        delete atom.label;\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "view = py3Dmol.view(width=800, height=800)\n",
        "view.setCameraParameters({'fov': 35, 'z': 100});\n",
        "\n",
        "# top hit for any pdb file and any smiles\n",
        "#top_hit = df_results.sort_values(\"diffdock_confidence\", ascending=False).iloc[0]\n",
        "#print(\"top hit:\")\n",
        "#display(top_hit)\n",
        "\n",
        "# add sdf\n",
        "view.addModel(open(top_sdf_file).read(), \"sdf\")\n",
        "view.setStyle({\"model\": 0}, {'stick':{\"color\":\"#ff0000\"}})\n",
        "view.setViewStyle({\"model\": 0}, {'style':'outline','color':'black','width':0.1})\n",
        "view.zoomTo();\n",
        "\n",
        "# add pdb\n",
        "view.addModel(open(pdb_file).read(), \"pdb\");\n",
        "view.setStyle({\"model\": 1}, {\"cartoon\":{\"color\":\"spectrum\"}})\n",
        "view.setStyle({\"model\": 1, \"hetflag\":True}, {'stick':{\"color\":\"spectrum\"}})\n",
        "\n",
        "model = view.getModel()\n",
        "model.setHoverable({}, True, resid_hover, unhover_func)\n",
        "\n",
        "view"
      ],
      "metadata": {
        "id": "-a1YL1AMavXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}